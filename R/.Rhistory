credito_treino = credito[amostra == 1,]
credito_teste = credito[amostra == 2,]
dim(credito_treino)
dim(credito_teste)
#criação do modelo
#parâmetros => variável de resposta ~ atributos explicativos, dataset
modelo = naiveBayes(class ~ . , credito_treino)
modelo
class(modelo)
#avaliação de desempenho
predicao = predict(modelo, credito_teste)
predicao
confusao = table(credito_teste$class, predicao)
confusao
#taxa de acertos
taxa_acertos = (confusao[1] + confusao[4]) / sum(confusao)
taxa_acertos
#taxa de erro
taxa_erros = (confusao[2] + confusao[3]) / sum(confusao)
taxa_erros
#simulando modelo em produção
novo_credito = read.csv(file.choose(), sep=",", header=T)
novo_credito
dim(novo_credito)
predict(modelo, novo_credito)
install.packages("rpart", dependencies=T)
library(rpart)
credito = read.csv(file.choose(), sep=",", header=T)
arvore = rpart(class ~ ., data=credito_treino, method="class")
print(arvore)
plot(arvore)
text(arvore, use.n=T, all=T, cex=.8)
teste = predict(arvore, newdata=credito_teste)
teste
#binarizando
cred = cbind(credito_teste, teste)
fix(cred)
cred['Result'] = ifele(cred$bad >= 0.5, "bad", "good")
cred['Result'] = ifelse(cred$bad >= 0.5, "bad", "good")
fix(cred)
#matriz de confusão
confusao = table(cred$class, cred$Result)
confusao
taxa_acerto = (confusao[1] + confusao[4]) / sum(confusao)
taxa_acerto
taxa_erro = (confusao[2] + confusao[3]) / sum(confusao)
taxa_erro
#usando SVM (support vector machine)
modelo = svm(class ~ ., credito_treino)
modelo
predicao = predict(modelo, credito_teste)
predicao
confusao = table(credito_teste$class, predicao)
confusao
taxa_acerto = (confusao[1] + confusao[4]) / sum(confusao)
taxa_acerto
taxa_erro = (confusao[2] + confusao[3]) / sum(confusao)
taxa_erro
#fazendo seleção de atributos
install.packages("FSelector", dependencies=T)
library(FSelector)
#fazendo seleção de atributos
install.packages("FSelector", dependencies=T)
library(FSelector)
random.forest.importance(class ~ ., credito)
#criando novo modelo após seleção
modelo = svm(class ~ checking_status + duration + credit_history + purpose, credito_treino)
predicao = predict(modelo, credito_teste)
#usando 4 atributos mais relevantes
confusao = table(credito_teste$class, predicao)
confusao
taxa_acerto = (confusao[1] + confusao[4]) / sum(confusao)
taxa_acerto
taxa_erro = (confusao[2] + confusao[3]) / sum(confusao)
taxa_erro
install.packages("class", dependencies=T)
install.packages("class", dependencies = T)
library(class)
head(iris)
summary(iris)
amostra = sample(2,150,replace=T,prob=c(0.7,0.3))
View(iris)
iris_treino = iris[amostra == 1,]
iris_teste = iris[amostra == 2,]
dim(iris_treino)
dim(iris_teste)
previsao = knn(iris_treino[,1:4], iris_treino[,5], k=3)
previsao = knn(iris_treino[,1:4], iris_teste[,5], k=3)
amostra = sample(2,150,replace=T,prob=c(0.7,0.3))
iris_treino = iris[amostra == 1,]
iris_teste = iris[amostra == 2,]
dim(iris_treino)
dim(iris_teste)
previsao = knn(iris_treino[,1:4], iris_teste[,5], k=3)
fim(iris)
fix(iris)
previsao = knn(iris_treino[,1:4], iris_teste[,1:4], iris_treino[,5], k=3)
table(iris_teste[,5], previsao)
install.packages("randomForest", dependencies=T)
library(randomForest)
floresta = randomForest(class ~ ., data=credito_treino, ntree=100, importance=T)
varImpPlot(floresta)
previsao = predict(floresta, credito_teste)
#matriz de confusão
confusao = table(previsao, credito_teste$class)
confusao
taxa_acerto = (confusao[1] + confusao[4]) / sum(confusao)
taxa_acerto
taxa_erro = (confusao[2] + confusao[3]) / sum(confusao)
taxa_erro
dim(iris)
head(iris)
summary(iris)
#pegando todas as colunas menos a classe e definindo o n de clusters como 3
cluster = kmeans(iris[1:4], center=3)
cluster
table(iris$Species, cluster$cluster)
cluster$cluster
plot(iris[,1:4], col=cluster$cluster)
#cada elemento pode estar em mais de um grupo
library(e1071)
cluster = cmeans(iris[1:4], center=3)
cluster
cluster
table(iris$Species, iris$cluster)
table(iris$Species, cluster$cluster)
install.packages("cluster", dependencies=T)
library(cluster)
cluster = pam(iris[,1:4], k=3)
cluster
plot(cluster)
table(iris$Species, cluster$clustering)
plot(cluster)
cluster
cluster = pam(iris[,1:4], k=3)
cluster
plot(cluster)
table(iris$Species, cluster$clustering)
install.packages("arules")
library(arules)
transacoes = read.transactions(file.choose(), format="basket", sep=",")
transacoes
inspect(transacoes)
image(transacoes)
regras = apriori(transacoes, parameter=list(supp=0.5, conf=0.5))
inspect(regras)
install.packages("arulesViz")
library(arulesViz)
plot(regras)
plot(regras, method="graph", control=list(type="items"))
#itens frequentes
transacoes2 = read.transactions(file.choose(), format="basket", sep=",")
image(transacoes2)
regras2 = eclat(transacoes, parameter=list(supp=0.1, maxlen=15))
regras2 = eclat(transacoes2, parameter=list(supp=0.1, maxlen=15))
inspect(regras2)
plot(regras, method="graph", control=list(type="items"))
install.packages("neuralnet")
library(neuralnet)
my_iris = iris
my_iris = cbind(my_iris, my_iris$Species=='setosa')
my_iris = cbind(my_iris, my_iris$Species=='versicolor')
my_iris = cbind(my_iris, my_iris$Species=='virginica')
summary(my_iris)
names(my_iris)[6] = 'setosa'
names(my_iris)[7] = 'versicolor'
names(my_iris)[8] = 'virginica'
summary(my_iris)
amostra = sample(2,150,replace=T,prob=c(0.7,0.3))
my_iris_treino = my_iris[amostra == 1]
my_iris_teste = my_iris[amostra == 2]
my_iris_treino = my_iris[amostra == 1,]
my_iris_teste = my_iris[amostra == 2,]
dim(my_iris_treino)
dim(my_iris_teste)
modelo = neuralnet(setosa + versicolor + virginica ~ Sepal.Length + Sepal.Width + Sepal.Length + Petal.Width, my_iris_treino, hidden=c(5,4))
print(modelo)
plot(modelo)
plot(modelo)
View(modelo)
teste = compute(modelo, my_iris_teste[,1:4])
modelo = neuralnet(setosa + versicolor + virginica ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, my_iris_treino, hidden=c(5,4))
plot(modelo)
teste = compute(modelo, my_iris_teste[,1:4])
teste$net.result
resultado = ad.data.frame(teste$net.result)
resultado = as.data.frame(teste$net.result)
resultado$class = colnames(resultado[,1:3])[max.col(resultado[,1:3, ties.method='first'])]
resultado$class = colnames(resultado[,1:3])[max.col(resultado[,1:3], ties.method='first')]
head(resultado)
sum(diag(confusao) * 100 / sum(confusao))
confusao
library(neuralnet)
my_iris = iris
my_iris = cbind(my_iris, my_iris$Species=='setosa')
my_iris = cbind(my_iris, my_iris$Species=='versicolor')
my_iris = cbind(my_iris, my_iris$Species=='virginica')
summary(my_iris)
names(my_iris)[6] = 'setosa'
names(my_iris)[7] = 'versicolor'
names(my_iris)[8] = 'virginica'
summary(my_iris)
amostra = sample(2,150,replace=T,prob=c(0.7,0.3))
my_iris_treino = my_iris[amostra == 1,]
my_iris_teste = my_iris[amostra == 2,]
dim(my_iris_treino)
dim(my_iris_teste)
modelo = neuralnet(setosa + versicolor + virginica ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, my_iris_treino, hidden=c(5,4))
plot(modelo)
teste = compute(modelo, my_iris_teste[,1:4])
teste$net.result
resultado = as.data.frame(teste$net.result)
names(resultado[1] = 'setosa')
names(resultado[2] = 'versicolor')
names(resultado[3] = 'virginica')
names(resultado)[1] = 'setosa'
names(resultado)[2] = 'versicolor'
names(resultado)[3] = 'virginica'
resultado$class = colnames(resultado[,1:3])[max.col(resultado[,1:3], ties.method='first')]
head(resultado)
confusao = table(resultado$class, my_iris_teste$Species)
sum(diag(confusao) * 100 / sum(confusao))
confusao
digitos = read.csv(gzfile(file.choose(), header=F))
digitos = read.csv(gzfile(file.choose()), header=F)
dim(digitos)
plot(modelo)
dim(digitos)
head(digitos)
split.screen(figs=c(2,2))
dig = t(matrix(unlist(digitos[20, -785], nrow=28, byrow=F)))
dig = t(matrix(unlist(digitos[20,-785]), nrow = 28, byrow = F))
dig = t(apply(dig, 2, rev))
dig
image(dig, col=grey.colors(s255))
image(dig, col=gray.colors(s255))
image(dig, col=grey.colors(255))
digitos[20,785]
screen(2)
dig = t(matrix(unlist(digitos[2,-785]), nrow = 28, byrow = F))
dig = t(matrix(unlist(digitos[2,-785]), nrow = 28, byrow = F))
image(dig, col=grey.colors(255))
digitos[2,785]
screen(3)
dig = t(matrix(unlist(digitos[4,-785]), nrow = 28, byrow = F))
image(dig, col=grey.colors(255))
digitos[4,785]
screen(4)
dig = t(matrix(unlist(digitos[5,-785]), nrow = 28, byrow = F))
image(dig, col=grey.colors(255))
digitos[5,785]
#treinamento da rede
install.packages("h2o")
library(h2o)
library(h2o)
h2o.init()
treino = h2o.importFile(file.choose())
h2o.init()
h2o.init()
treino = h2o.importFile(file.choose())
teste = h2o.importFile(file.choose())
treino = h2o.importFile(file.choose())
teste = h2o.importFile(file.choose())
treino[,785] = as.factor(treino[,785])
teste[,785] = as.factor(teste[,785])
modelo = h2o.deeplearning(x=colnames(treino[,1:784], y="C785", training_frame=treino, validation_frame=teste, distribution="AUTO", activation="RectifierWithDropout", hidden=c(64,64,64), sparse=TRUE, epochs=20))
modelo = h2o.deeplearning(x=colnames(treino[,1:784]), y="C785", training_frame=treino, validation_frame=teste, distribution="AUTO", activation="RectifierWithDropout", hidden=c(64,64,64), sparse=TRUE, epochs=20)
plot(modelo)
plot(modelo)
close.screen(n, all.screens = FALSE)
close.screen(4, all.screens = FALSE)
plot(modelo)
close.screen(all=T)
plot(modelo)
h2o.performance(modelo)
treino[20,785]
pred = h2o.predict(modelo, newdata=treino[20,1:784])
pred$predict
plot(trees)
#dividindo a tela
split.screen(figs=c(2,2))
screen(1)
plot(trees$Girth, trees$Volume)
#dividindo a tela
split.screen(figs=c(2,2))
screen(1)
plot(trees$Girth, trees$Volume)
screen(2)
plot(trees$Girth, trees$Height)
screen(3)
plot(trees$Height, trees$Volume)
screen(4)
hist(trees$Volume)
#voltando tela
close.screen(all=TRUE)
boxplot(trees$Volume, main="Árvores", xlab="Volume")
boxplot(trees$Volume, main="Árvores", xlab="Volume", col="blue", horizontal=T)
boxplot(trees$Volume, main="Árvores", xlab="Volume", col="blue", horizontal=T, outline=F)
boxplot(trees$Volume, main="Árvores", xlab="Volume", col="blue", horizontal=T, outline=F, notch=T)
boxplot.stats(trees$Height)
boxplot(trees)
boxplot(trees, horizontal=T)
InsectSprays
spray =  aggregate(. ~ spray, data=InsectSprays, sum)
spray
#gráfico de barras
barplot(spray$count, col=gray.colors(6), xlab="Spray", ylab="Total", names.arg=spray$spray)
box()
#gráfico de setor (pizza)
pie(spray$count, labels=spray$spray, main="Spray", col=c(1:6))
legend("bottomright", legend=spray$spray, cex=1, fill=c(1:6))
pie(spray$count, labels=NA, main="Spray", col=c(1:6))
legend("bottomright", legend=spray$spray, cex=1, fill=c(1:6))
pie(spray$count, labels=NA, main="Spray", col=c(1:6))
legend("bottomright", legend=spray$spray, cex=1, fill=c(1:6))
#boxplot com Lattice
library(lattice)
bwplot(trees$Volume)
bwplot(trees$Volume main="Árvores", xlab="Volume")
bwplot(trees$Volume, main="Árvores", xlab="Volume")
#histograma com Lattice
library(lattice)
histogram(trees$Volume, main="Árvores", xlab="Volume", aspect=2, type="count", nint=10)
histogram(trees$Volume, main="Árvores", xlab="Volume", aspect=1, type="count", nint=10)
histogram(trees$Volume, main="Árvores", xlab="Volume", aspect=0.5, type="count", nint=10)
#usando chickwts para fazer histograma condicional
aggregate(chickwts$weight, by=list(chickwts$feed), FUN=sum)
histogram(~weight | feed, data=chickwts)
densityplot(CO2$conc)
density(~ CO2$conc | CO2$Treatment)
densityplot(~ CO2$conc | CO2$Treatment)
densityplot(~ CO2$conc | CO2$Treatment, plot.points=F)
#dispersão com Lattice
xyplot(CO2$conc ~ CO2$uptake)
xyplot(CO2$conc ~ CO2$uptake | CO2$Type)
xyplot(CO2$conc ~ CO2$uptake | CO2$Treatment)
esoph
dotplot(esoph$alcgp ~ esoph$controls, data=esoph)
dotplot(esoph$alcgp ~ esoph$ncontrols, data=esoph)
dotplot(esoph$alcgp ~ esoph$ncontrols | esoph$tobgp, data=esoph)
library(lattice)
cloud(decrease ~ rowpos * colpos, data=OrchardSprays)
cloud(decrease ~ rowpos * colpos, groups=treatment, data=OrchardSprays)
set.seed(2345)
sample(c(1000), 2)
set.seed(2345)
sample(c(100), 1)
sample(c(1000), 2)
set.seed(2345)
sample(c(1000), 2)
set.seed(2345)
sample(c(1000), 2)
#14
0.364454993*(1354.17 / 15.3348)
#17
2263.818 - (32.18395 * 38.54545)
#22
7/8
#29
ppois(2,3, lower.tail=F)
#29
ppois(3,2, lower.tail=F)
#58
ppois(3,2)
#61
pnorm(8,4,6)
#61
pnorm(6,8,4)
#66
1221 / 1324
#70
dbinom(3,6,0.25)
#72
dbinom(0,4,0.5) + dbinom(4,4,0.5)
#73
nums = c(1041,881,1007,895,761,1036,1114,980,970,1062)
sd(nums)
#80
4 / 52
#87
pnorm(6,8,4) + pnorm(10,8,4,lower.tail=F)
#variável independente = speed; variável dependente = dist
dim(cars)
head(cars)
#correlação
cor(cars)
#94
d1 = c(18,20,21,28,33,38,43,48,53,58,63)
d2 = c(871,1132,5435,1200,1356,1488,1600,2130,2454,3066,4090)
cor(d1,d2)
#carrega Credito.csv
credito = read.csv(file.choose(),sep=';',header=T)
treino = credito[amostra==1,]
teste = credito[amostra==2,]
treino
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ .,data=treino, ntree=100,proximity=T)
library(randomForest)
install.packages('randomForest',dependencies=T)
install.packages("randomForest", dependencies = T)
library(randomForest)
library(randomForest)
library(randomForest)
install.packages("randomForest",dependencies=T)
library(randomForest)
#carrega Credito.csv
credito = read.csv(file.choose(),sep=';',header=T)
#amostragem de treino e teste
amostra = sample(2,1000,replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ .,data=treino, ntree=100,proximity=T)
#previsão
previsao = predict(floresta, teste)
#matriz de confusao
floresta$confusion
#taxa de erro
erro = (floresta$confusion[2] + floresta$confusion[3]) / sum(floresta$confusion)
erro
#amostragem de treino e teste
amostra = sample(2,1000,replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ .,data=treino, ntree=100,proximity=T)
#previsão
previsao = predict(floresta, teste)
#matriz de confusao
floresta$confusion
#taxa de erro aceitável
erro = (floresta$confusion[2] + floresta$confusion[3]) / sum(floresta$confusion)
erro
#amostragem de treino e teste
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ ., data=treino, ntree=500, proximity=T)
library(randomForest)
#carrega Credito.csv
credito = read.csv(file.choose(), sep=';', header=T)
#amostragem de treino e teste
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
#amostragem de treino e teste
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ ., data=treino, ntree=500, proximity=T)
#previsão
previsao = predict(floresta, teste)
#matriz de confusao
floresta$confusion
#taxa de erro aceitável (23%)
erro = (floresta$confusion[2] + floresta$confusion[3]) / sum(floresta$confusion)
erro
#amostragem de treino e teste
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ ., data=treino, ntree=400, proximity=T)
#previsão
previsao = predict(floresta, teste)
#matriz de confusao
floresta$confusion
#taxa de erro aceitável (23%)
erro = (floresta$confusion[2] + floresta$confusion[3]) / sum(floresta$confusion)
erro
#amostragem de treino e teste
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ ., data=treino, ntree=300, proximity=T)
#previsão
previsao = predict(floresta, teste)
#matriz de confusao
floresta$confusion
#taxa de erro aceitável (23%)
erro = (floresta$confusion[2] + floresta$confusion[3]) / sum(floresta$confusion)
erro
#amostragem de treino e teste
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ ., data=treino, ntree=200, proximity=T)
#previsão
previsao = predict(floresta, teste)
#matriz de confusao
floresta$confusion
#taxa de erro aceitável (23%)
erro = (floresta$confusion[2] + floresta$confusion[3]) / sum(floresta$confusion)
erro

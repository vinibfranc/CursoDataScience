regras2 = eclat(transacoes, parameter=list(supp=0.1, maxlen=15))
regras2 = eclat(transacoes2, parameter=list(supp=0.1, maxlen=15))
inspect(regras2)
plot(regras, method="graph", control=list(type="items"))
install.packages("neuralnet")
library(neuralnet)
my_iris = iris
my_iris = cbind(my_iris, my_iris$Species=='setosa')
my_iris = cbind(my_iris, my_iris$Species=='versicolor')
my_iris = cbind(my_iris, my_iris$Species=='virginica')
summary(my_iris)
names(my_iris)[6] = 'setosa'
names(my_iris)[7] = 'versicolor'
names(my_iris)[8] = 'virginica'
summary(my_iris)
amostra = sample(2,150,replace=T,prob=c(0.7,0.3))
my_iris_treino = my_iris[amostra == 1]
my_iris_teste = my_iris[amostra == 2]
my_iris_treino = my_iris[amostra == 1,]
my_iris_teste = my_iris[amostra == 2,]
dim(my_iris_treino)
dim(my_iris_teste)
modelo = neuralnet(setosa + versicolor + virginica ~ Sepal.Length + Sepal.Width + Sepal.Length + Petal.Width, my_iris_treino, hidden=c(5,4))
print(modelo)
plot(modelo)
plot(modelo)
View(modelo)
teste = compute(modelo, my_iris_teste[,1:4])
modelo = neuralnet(setosa + versicolor + virginica ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, my_iris_treino, hidden=c(5,4))
plot(modelo)
teste = compute(modelo, my_iris_teste[,1:4])
teste$net.result
resultado = ad.data.frame(teste$net.result)
resultado = as.data.frame(teste$net.result)
resultado$class = colnames(resultado[,1:3])[max.col(resultado[,1:3, ties.method='first'])]
resultado$class = colnames(resultado[,1:3])[max.col(resultado[,1:3], ties.method='first')]
head(resultado)
sum(diag(confusao) * 100 / sum(confusao))
confusao
library(neuralnet)
my_iris = iris
my_iris = cbind(my_iris, my_iris$Species=='setosa')
my_iris = cbind(my_iris, my_iris$Species=='versicolor')
my_iris = cbind(my_iris, my_iris$Species=='virginica')
summary(my_iris)
names(my_iris)[6] = 'setosa'
names(my_iris)[7] = 'versicolor'
names(my_iris)[8] = 'virginica'
summary(my_iris)
amostra = sample(2,150,replace=T,prob=c(0.7,0.3))
my_iris_treino = my_iris[amostra == 1,]
my_iris_teste = my_iris[amostra == 2,]
dim(my_iris_treino)
dim(my_iris_teste)
modelo = neuralnet(setosa + versicolor + virginica ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, my_iris_treino, hidden=c(5,4))
plot(modelo)
teste = compute(modelo, my_iris_teste[,1:4])
teste$net.result
resultado = as.data.frame(teste$net.result)
names(resultado[1] = 'setosa')
names(resultado[2] = 'versicolor')
names(resultado[3] = 'virginica')
names(resultado)[1] = 'setosa'
names(resultado)[2] = 'versicolor'
names(resultado)[3] = 'virginica'
resultado$class = colnames(resultado[,1:3])[max.col(resultado[,1:3], ties.method='first')]
head(resultado)
confusao = table(resultado$class, my_iris_teste$Species)
sum(diag(confusao) * 100 / sum(confusao))
confusao
digitos = read.csv(gzfile(file.choose(), header=F))
digitos = read.csv(gzfile(file.choose()), header=F)
dim(digitos)
plot(modelo)
dim(digitos)
head(digitos)
split.screen(figs=c(2,2))
dig = t(matrix(unlist(digitos[20, -785], nrow=28, byrow=F)))
dig = t(matrix(unlist(digitos[20,-785]), nrow = 28, byrow = F))
dig = t(apply(dig, 2, rev))
dig
image(dig, col=grey.colors(s255))
image(dig, col=gray.colors(s255))
image(dig, col=grey.colors(255))
digitos[20,785]
screen(2)
dig = t(matrix(unlist(digitos[2,-785]), nrow = 28, byrow = F))
dig = t(matrix(unlist(digitos[2,-785]), nrow = 28, byrow = F))
image(dig, col=grey.colors(255))
digitos[2,785]
screen(3)
dig = t(matrix(unlist(digitos[4,-785]), nrow = 28, byrow = F))
image(dig, col=grey.colors(255))
digitos[4,785]
screen(4)
dig = t(matrix(unlist(digitos[5,-785]), nrow = 28, byrow = F))
image(dig, col=grey.colors(255))
digitos[5,785]
#treinamento da rede
install.packages("h2o")
library(h2o)
library(h2o)
h2o.init()
treino = h2o.importFile(file.choose())
h2o.init()
h2o.init()
treino = h2o.importFile(file.choose())
teste = h2o.importFile(file.choose())
treino = h2o.importFile(file.choose())
teste = h2o.importFile(file.choose())
treino[,785] = as.factor(treino[,785])
teste[,785] = as.factor(teste[,785])
modelo = h2o.deeplearning(x=colnames(treino[,1:784], y="C785", training_frame=treino, validation_frame=teste, distribution="AUTO", activation="RectifierWithDropout", hidden=c(64,64,64), sparse=TRUE, epochs=20))
modelo = h2o.deeplearning(x=colnames(treino[,1:784]), y="C785", training_frame=treino, validation_frame=teste, distribution="AUTO", activation="RectifierWithDropout", hidden=c(64,64,64), sparse=TRUE, epochs=20)
plot(modelo)
plot(modelo)
close.screen(n, all.screens = FALSE)
close.screen(4, all.screens = FALSE)
plot(modelo)
close.screen(all=T)
plot(modelo)
h2o.performance(modelo)
treino[20,785]
pred = h2o.predict(modelo, newdata=treino[20,1:784])
pred$predict
plot(trees)
#dividindo a tela
split.screen(figs=c(2,2))
screen(1)
plot(trees$Girth, trees$Volume)
#dividindo a tela
split.screen(figs=c(2,2))
screen(1)
plot(trees$Girth, trees$Volume)
screen(2)
plot(trees$Girth, trees$Height)
screen(3)
plot(trees$Height, trees$Volume)
screen(4)
hist(trees$Volume)
#voltando tela
close.screen(all=TRUE)
boxplot(trees$Volume, main="Árvores", xlab="Volume")
boxplot(trees$Volume, main="Árvores", xlab="Volume", col="blue", horizontal=T)
boxplot(trees$Volume, main="Árvores", xlab="Volume", col="blue", horizontal=T, outline=F)
boxplot(trees$Volume, main="Árvores", xlab="Volume", col="blue", horizontal=T, outline=F, notch=T)
boxplot.stats(trees$Height)
boxplot(trees)
boxplot(trees, horizontal=T)
InsectSprays
spray =  aggregate(. ~ spray, data=InsectSprays, sum)
spray
#gráfico de barras
barplot(spray$count, col=gray.colors(6), xlab="Spray", ylab="Total", names.arg=spray$spray)
box()
#gráfico de setor (pizza)
pie(spray$count, labels=spray$spray, main="Spray", col=c(1:6))
legend("bottomright", legend=spray$spray, cex=1, fill=c(1:6))
pie(spray$count, labels=NA, main="Spray", col=c(1:6))
legend("bottomright", legend=spray$spray, cex=1, fill=c(1:6))
pie(spray$count, labels=NA, main="Spray", col=c(1:6))
legend("bottomright", legend=spray$spray, cex=1, fill=c(1:6))
#boxplot com Lattice
library(lattice)
bwplot(trees$Volume)
bwplot(trees$Volume main="Árvores", xlab="Volume")
bwplot(trees$Volume, main="Árvores", xlab="Volume")
#histograma com Lattice
library(lattice)
histogram(trees$Volume, main="Árvores", xlab="Volume", aspect=2, type="count", nint=10)
histogram(trees$Volume, main="Árvores", xlab="Volume", aspect=1, type="count", nint=10)
histogram(trees$Volume, main="Árvores", xlab="Volume", aspect=0.5, type="count", nint=10)
#usando chickwts para fazer histograma condicional
aggregate(chickwts$weight, by=list(chickwts$feed), FUN=sum)
histogram(~weight | feed, data=chickwts)
densityplot(CO2$conc)
density(~ CO2$conc | CO2$Treatment)
densityplot(~ CO2$conc | CO2$Treatment)
densityplot(~ CO2$conc | CO2$Treatment, plot.points=F)
#dispersão com Lattice
xyplot(CO2$conc ~ CO2$uptake)
xyplot(CO2$conc ~ CO2$uptake | CO2$Type)
xyplot(CO2$conc ~ CO2$uptake | CO2$Treatment)
esoph
dotplot(esoph$alcgp ~ esoph$controls, data=esoph)
dotplot(esoph$alcgp ~ esoph$ncontrols, data=esoph)
dotplot(esoph$alcgp ~ esoph$ncontrols | esoph$tobgp, data=esoph)
library(lattice)
cloud(decrease ~ rowpos * colpos, data=OrchardSprays)
cloud(decrease ~ rowpos * colpos, groups=treatment, data=OrchardSprays)
set.seed(2345)
sample(c(1000), 2)
set.seed(2345)
sample(c(100), 1)
sample(c(1000), 2)
set.seed(2345)
sample(c(1000), 2)
set.seed(2345)
sample(c(1000), 2)
#14
0.364454993*(1354.17 / 15.3348)
#17
2263.818 - (32.18395 * 38.54545)
#22
7/8
#29
ppois(2,3, lower.tail=F)
#29
ppois(3,2, lower.tail=F)
#58
ppois(3,2)
#61
pnorm(8,4,6)
#61
pnorm(6,8,4)
#66
1221 / 1324
#70
dbinom(3,6,0.25)
#72
dbinom(0,4,0.5) + dbinom(4,4,0.5)
#73
nums = c(1041,881,1007,895,761,1036,1114,980,970,1062)
sd(nums)
#80
4 / 52
#87
pnorm(6,8,4) + pnorm(10,8,4,lower.tail=F)
#variável independente = speed; variável dependente = dist
dim(cars)
head(cars)
#correlação
cor(cars)
#94
d1 = c(18,20,21,28,33,38,43,48,53,58,63)
d2 = c(871,1132,5435,1200,1356,1488,1600,2130,2454,3066,4090)
cor(d1,d2)
#carrega Credito.csv
credito = read.csv(file.choose(),sep=';',header=T)
treino = credito[amostra==1,]
teste = credito[amostra==2,]
treino
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ .,data=treino, ntree=100,proximity=T)
library(randomForest)
install.packages('randomForest',dependencies=T)
install.packages("randomForest", dependencies = T)
library(randomForest)
library(randomForest)
library(randomForest)
install.packages("randomForest",dependencies=T)
library(randomForest)
#carrega Credito.csv
credito = read.csv(file.choose(),sep=';',header=T)
#amostragem de treino e teste
amostra = sample(2,1000,replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ .,data=treino, ntree=100,proximity=T)
#previsão
previsao = predict(floresta, teste)
#matriz de confusao
floresta$confusion
#taxa de erro
erro = (floresta$confusion[2] + floresta$confusion[3]) / sum(floresta$confusion)
erro
#amostragem de treino e teste
amostra = sample(2,1000,replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ .,data=treino, ntree=100,proximity=T)
#previsão
previsao = predict(floresta, teste)
#matriz de confusao
floresta$confusion
#taxa de erro aceitável
erro = (floresta$confusion[2] + floresta$confusion[3]) / sum(floresta$confusion)
erro
#amostragem de treino e teste
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ ., data=treino, ntree=500, proximity=T)
library(randomForest)
#carrega Credito.csv
credito = read.csv(file.choose(), sep=';', header=T)
#amostragem de treino e teste
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
#amostragem de treino e teste
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ ., data=treino, ntree=500, proximity=T)
#previsão
previsao = predict(floresta, teste)
#matriz de confusao
floresta$confusion
#taxa de erro aceitável (23%)
erro = (floresta$confusion[2] + floresta$confusion[3]) / sum(floresta$confusion)
erro
#amostragem de treino e teste
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ ., data=treino, ntree=400, proximity=T)
#previsão
previsao = predict(floresta, teste)
#matriz de confusao
floresta$confusion
#taxa de erro aceitável (23%)
erro = (floresta$confusion[2] + floresta$confusion[3]) / sum(floresta$confusion)
erro
#amostragem de treino e teste
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ ., data=treino, ntree=300, proximity=T)
#previsão
previsao = predict(floresta, teste)
#matriz de confusao
floresta$confusion
#taxa de erro aceitável (23%)
erro = (floresta$confusion[2] + floresta$confusion[3]) / sum(floresta$confusion)
erro
#amostragem de treino e teste
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
treino = credito[amostra==1,]
teste = credito[amostra==2,]
dim(treino)
dim(teste)
#modelo
floresta = randomForest(CLASSE ~ ., data=treino, ntree=200, proximity=T)
#previsão
previsao = predict(floresta, teste)
#matriz de confusao
floresta$confusion
#taxa de erro aceitável (23%)
erro = (floresta$confusion[2] + floresta$confusion[3]) / sum(floresta$confusion)
erro
install.packages("e1071", dependencies=TRUE)
library(e1071)
install.packages("C:/Users/vinif/Downloads/e1071_1.7-0.1.zip", repos = NULL, type = "win.binary")
getwd()
# alterando o diretório padrão
setwd("C:/Users/vinif/Desktop/CursoDataScience/R/fundamentos")
# saber o diretório padrão
getwd()
# encerrando
quit()
# classes
class(iris)
# alterando o diretório padrão
setwd("C:/Users/vinif/Desktop/CursoDataScience/R")
class(iris)
iristeste = iris
save(iristeste, file="iristeste.Rdata")
rm(iristeste)
save(iristeste, file="iristeste.Rdata")
iristeste = iris
save(iristeste, file="iristeste.Rdata")
rm(iristeste)
load(file="iristeste.Rdata")
iristeste
x = c(12, 34, 16, 79)
y = c(1, 6, 9, 14)
plot(x, y)
quit()
delta <- 8 #ponto flutuante
delta <- 8L #inteiro
logico <- TRUE
logico <- F
caractere <- "Texto"
delta <- 8
class(delta)
delta = 8L
class(delta)
logico = TRUE
logico = F
caractere <- "Texto"
caractere <- 'Texto'
c <- 2
d <- 4
(c + d) * d
e <- (c + d) * d
e
a <- 1
b <- 2
a < b
a == b
sqrt(2500)
# Vetores
x <- c(1, 2, 3, 4, 5, 6)
x
x[1]
x[1] <- 10
x
# Matrizes (duas dimensões)
volcano[1, 2]
# Listas (objetos encadeados de classes diferentes)
Harman23.cor[1]
Harman23.cor[2]
# Fatores (variáveis categóricas)
Dados = c(1, 2 , 3)
Dados = fator(dados)
# vetores
x <- c(1, 2, 3, 4, 5, 6)
x
x[1]
x[1] <- 10
x[1]
# outros tipos de vetores
y <- c("a", "b", "c", "d")
y
z = c(1L, 2L, 3L)
z
# matrizes
VADeaths
colnames(VADeaths)
rownames(VADeaths)
# só coluna 1
VADeaths[,1]
# só linha 1
VADeaths[1,]
# linhas de 1 até 3
VADeaths[1:3,]
# deataframes
longley
longley$Unemployed
longley["unemployed"]
longley['unemployed']
longley['Unemployed']
ability.cov$cov
ability.cov[1]
class(ability.cov$cov)
class(ability.cov$center)
ability.cov$cov[, 1:3]
# fatores
state.region
sd(x)
# argumentos
head(x=iris, n=2)
head(iris)
head(iris, 2)
head(n=22)
head(x=iris, n=2)
head(iris)
head(iris, 2)
head(n=22)
x
# texto
x = read.csv(file.choose(), header = TRUE, sep=";")
# odbc
install.packages("RODBC")
load(RODBC)
library(RODBC)
# planilha
install.packages("xlsx")
library(xlsx)
dados = read.xlsx(file.choose(), sheetIndex=1)
# arff
install.packages("foreign")
library(foreign)
dados = read.arff(file.choose())
a = 10
b = 20
if(a > 10) {
print("A é maior que 10")
}else{
print("A não é maior")
}
x = ifesle(a > 10, "A é maior", "A não é maior")
x = ifelse(a > 10, "A é maior", "A não é maior")
x
print(i)
for(i in 1:10) {
print(i)
}
a = a+1
while(a <= 10) {
print(a)
a = a+1
}
a = 1
while(a <= 10) {
print(a)
a = a+1
}
parOuImpar <- function(x) {
return(ifelse(x %% 2 == 0, "Par", "Impar"))
}
parOuImpar(5)
parOuImpar(12)

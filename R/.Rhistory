#conjunto de dados, quantidade de aleatórios, com ou sem repo, vetor de probabilidade
amostra = sample(c(0,1), 150, replace=TRUE, prob=c(0.5, 0.5))
amostra
length(amostra[amostra==1])
length(amostra[amostra==0])
set.seed(2345)
sample(c(100), 1)
jogadores = c(40000, 18000, 12000, 250000, 30000, 140000, 300000, 40000, 800000)
mean(jogadores)
median(jogadores)
quartis = quantile(jogadores)
quartis
sd(jogadores)
summary(jogadores)
#n de sucessos, n de experimentos, probabilidade
dbinom(3, 5, 0.5)
# 4 sinais de 4 tempos, prob = 0,1,2,3,4 sinais verdes?
dbinom(0, 4, 0.25)
dbinom(1, 4, 0.25)
dbinom(2, 4, 0.25)
dbinom(3, 4, 0.25)
dbinom(4, 4, 0.25)
#probabilidade cumulativa
pbinom(4,4, 0.25)
# prova 12 questões, acertar no chute 7 sendo que cada uma tem 4 alternativas
dbinom(7,12,0.25)
dbinom(12,12,0.25)
#média = 8, dp = 2; objeto < 6 kg
pnorm(6,8,2)
#média = 8, dp = 2; objeto > 6 kg
pnorm(6,8,2,lower.tail=F)
#ou
1 - pnorm(6,8,2)
#menos de 6 ou mais de 10 kg
pnorm(6,8,2) + pnorm(10,8,2,lower.tail=F)
#menos de 10 kg e mais de 8kg
pnorm(10,8,2) - pnorm(8,8,2)
#dados aleatórios normalmente distribuídos
x = xnorm(100)
#dados aleatórios normalmente distribuídos
x = rnorm(100)
x
#diagrama de normalidade
qqnorm(x)
qqline(x)
shapiro.test(x)
#média=75, amostra=9, dp=10, salario > 80 por hora?
pt(1.5, 8, lower.tail=F)
1 - pt(1.5, 8)
#6
(1500 - 1250) / 480
#6
pnorm(1500,1250,480)
#3
x = c (22,10,12,14,13,15)
median(x)
#Questão 4
dbinom(8,10,0.5)
#Questão 4
13/52
eleicao = read.csv(file.choose(), sep=";", header=T)
fix(eleicao)
plot(eleicao$DESPESAS, eleicao$SITUACAO)
summary(eleicao)
cor(eleicao$DESPESAS, eleicao$SITUACAO)
modelo = glm(SITUACAO ~ DESPESAS, data=eleicao, family="binomial")
summary(modelo)
plot(eleicao$DESPESAS, eleicao$SITUACAO, col='red', pch=20)
points(eleicao$DESPESAS, modelo$fitted.values, pch=4)
#prever com base em novos candidatos
prever_eleicao = read.csv(file.choose(), sep=";", header=T)
fix(prever_eleicao)
prever_eleicao$RESULT = predict(modelo, newdata=prever_eleicao, type="response")
prever_eleicao$RESULT
fix(prever_eleicao)
novela = matrix(c(19,6,43,32), nrow=2, byrow=T)
fix(novela)
rownames(novela) = c('Masculino','Feminino')
colnames(novela) = c('Assiste','Não assiste')
fix(novela)
chisq.test()
chisq.test(novela)
tratamento = read.csv(file.choose(), se=';', header=T)
fix(tratamento)
boxplot(tratamento$Horas ~ tratamento$Remedio)
#Anova de 1 fator
an = aov(Horas ~ Remedio, data=tratamento)
summary(an)
#Anova de 2 fatores
an2 = aov(Horas ~ Remedio * Sexo, data=tratamento)
summary(an2)
tukey = TukeyHSD(an)
tukey
plot(tukey)
boxplot(iris$Sepal.Width)
#sem outliers
boxplot(iris$Sepal.Width, outline=F)
#ver números do boxplot
boxplot.stats(iris$Sepal.Width)$out
#pacote outliers
install.packages('outliers')
library(outliers)
outlier(iris$Sepal.Width)
outlier(iris$Sepal.Width, opposite=T)
#Questão 2
dpois(12,10)
#Questão 4
jogos = matrix(c(41,34,18,7), nrow=2, byrow=T)
fix(jogos)
rownames(jogos) = c('Masculino','Feminino')
colnames(jogos) = c('Joga','Não joga')
fix(jogos)
chisq.test(jogos)
AirPassengers
AirPassengers
start(AirPassengers)
end(AirPassengers)
plot(AirPassengers)
plot(aggregate(AirPassengers))
monthplot(AirPassengers)
subst = window(AirPassengers, start=c(1960,1), end=c(1960,12))
subst
subst
#analisar somente em 1960
subst = window(AirPassengers, start=c(1960,1), end=c(1960,12))
plot(subst)
plot(AirPassengers)
#elemento de tendência, elemento de sazonalidade e elemento de aleatoriedade
dec = decompose(AirPassengers)
dec
dec$seasonal
dec$trend
dec$random
plot(dec$seasonal)
plot(dec$trend)
plot(dec$random)
plot(dec)
AirPassengers
#modo mais simples
mean(AirPassengers)
mean(window(AirPassengers, start=c(1960,1), end=c(1960,2)))
#média móvel (vai se ajustando)
install.packages('forecast')
library(forecast)
media_movel = ma(AirPassengers, order=12)
media_movel
previsao = forecast(media_movel, h=12)
previsao
plot(previsao)
arima
previsao2 = forecast(arima, h=12)
previsao2
previsao2 = forecast(arima, h=12)
previsao2
arima = auto.arima(AirPassengers)
arima
previsao2 = forecast(arima, h=12)
previsao2
plot(previsao2)
#pacotes: e1071 e klaR
install.packages("e1071", dependencies=T)
library(e1071)
credito = read.csv(file.choose(), se=",", header=T)
head(credito)
dim(credito)
#divisão de treino e teste (70/30)
amostra = sample(2, 1000, replace=T, prob=c(0.7,0.3))
amostra
amostra[amostra == 1]
credito_treino = credito[amostra == 1,]
credito_teste = credito[amostra == 2,]
dim(credito_treino)
dim(credito_teste)
#criação do modelo
#parâmetros => variável de resposta ~ atributos explicativos, dataset
modelo = naiveBayes(class ~ . , credito_treino)
modelo
class(modelo)
#avaliação de desempenho
predicao = predict(modelo, credito_teste)
predicao
confusao = table(credito_teste$class, predicao)
confusao
#taxa de acertos
taxa_acertos = (confusao[1] + confusao[4]) / sum(confusao)
taxa_acertos
#taxa de erro
taxa_erros = (confusao[2] + confusao[3]) / sum(confusao)
taxa_erros
#simulando modelo em produção
novo_credito = read.csv(file.choose(), sep=",", header=T)
novo_credito
dim(novo_credito)
predict(modelo, novo_credito)
install.packages("rpart", dependencies=T)
library(rpart)
credito = read.csv(file.choose(), sep=",", header=T)
arvore = rpart(class ~ ., data=credito_treino, method="class")
print(arvore)
plot(arvore)
text(arvore, use.n=T, all=T, cex=.8)
teste = predict(arvore, newdata=credito_teste)
teste
#binarizando
cred = cbind(credito_teste, teste)
fix(cred)
cred['Result'] = ifele(cred$bad >= 0.5, "bad", "good")
cred['Result'] = ifelse(cred$bad >= 0.5, "bad", "good")
fix(cred)
#matriz de confusão
confusao = table(cred$class, cred$Result)
confusao
taxa_acerto = (confusao[1] + confusao[4]) / sum(confusao)
taxa_acerto
taxa_erro = (confusao[2] + confusao[3]) / sum(confusao)
taxa_erro
#usando SVM (support vector machine)
modelo = svm(class ~ ., credito_treino)
modelo
predicao = predict(modelo, credito_teste)
predicao
confusao = table(credito_teste$class, predicao)
confusao
taxa_acerto = (confusao[1] + confusao[4]) / sum(confusao)
taxa_acerto
taxa_erro = (confusao[2] + confusao[3]) / sum(confusao)
taxa_erro
#fazendo seleção de atributos
install.packages("FSelector", dependencies=T)
library(FSelector)
#fazendo seleção de atributos
install.packages("FSelector", dependencies=T)
library(FSelector)
random.forest.importance(class ~ ., credito)
#criando novo modelo após seleção
modelo = svm(class ~ checking_status + duration + credit_history + purpose, credito_treino)
predicao = predict(modelo, credito_teste)
#usando 4 atributos mais relevantes
confusao = table(credito_teste$class, predicao)
confusao
taxa_acerto = (confusao[1] + confusao[4]) / sum(confusao)
taxa_acerto
taxa_erro = (confusao[2] + confusao[3]) / sum(confusao)
taxa_erro
install.packages("class", dependencies=T)
install.packages("class", dependencies = T)
library(class)
head(iris)
summary(iris)
amostra = sample(2,150,replace=T,prob=c(0.7,0.3))
View(iris)
iris_treino = iris[amostra == 1,]
iris_teste = iris[amostra == 2,]
dim(iris_treino)
dim(iris_teste)
previsao = knn(iris_treino[,1:4], iris_treino[,5], k=3)
previsao = knn(iris_treino[,1:4], iris_teste[,5], k=3)
amostra = sample(2,150,replace=T,prob=c(0.7,0.3))
iris_treino = iris[amostra == 1,]
iris_teste = iris[amostra == 2,]
dim(iris_treino)
dim(iris_teste)
previsao = knn(iris_treino[,1:4], iris_teste[,5], k=3)
fim(iris)
fix(iris)
previsao = knn(iris_treino[,1:4], iris_teste[,1:4], iris_treino[,5], k=3)
table(iris_teste[,5], previsao)
install.packages("randomForest", dependencies=T)
library(randomForest)
floresta = randomForest(class ~ ., data=credito_treino, ntree=100, importance=T)
varImpPlot(floresta)
previsao = predict(floresta, credito_teste)
#matriz de confusão
confusao = table(previsao, credito_teste$class)
confusao
taxa_acerto = (confusao[1] + confusao[4]) / sum(confusao)
taxa_acerto
taxa_erro = (confusao[2] + confusao[3]) / sum(confusao)
taxa_erro
dim(iris)
head(iris)
summary(iris)
#pegando todas as colunas menos a classe e definindo o n de clusters como 3
cluster = kmeans(iris[1:4], center=3)
cluster
table(iris$Species, cluster$cluster)
cluster$cluster
plot(iris[,1:4], col=cluster$cluster)
#cada elemento pode estar em mais de um grupo
library(e1071)
cluster = cmeans(iris[1:4], center=3)
cluster
cluster
table(iris$Species, iris$cluster)
table(iris$Species, cluster$cluster)
install.packages("cluster", dependencies=T)
library(cluster)
cluster = pam(iris[,1:4], k=3)
cluster
plot(cluster)
table(iris$Species, cluster$clustering)
plot(cluster)
cluster
cluster = pam(iris[,1:4], k=3)
cluster
plot(cluster)
table(iris$Species, cluster$clustering)
install.packages("arules")
library(arules)
transacoes = read.transactions(file.choose(), format="basket", sep=",")
transacoes
inspect(transacoes)
image(transacoes)
regras = apriori(transacoes, parameter=list(supp=0.5, conf=0.5))
inspect(regras)
install.packages("arulesViz")
library(arulesViz)
plot(regras)
plot(regras, method="graph", control=list(type="items"))
#itens frequentes
transacoes2 = read.transactions(file.choose(), format="basket", sep=",")
image(transacoes2)
regras2 = eclat(transacoes, parameter=list(supp=0.1, maxlen=15))
regras2 = eclat(transacoes2, parameter=list(supp=0.1, maxlen=15))
inspect(regras2)
plot(regras, method="graph", control=list(type="items"))
install.packages("neuralnet")
library(neuralnet)
my_iris = iris
my_iris = cbind(my_iris, my_iris$Species=='setosa')
my_iris = cbind(my_iris, my_iris$Species=='versicolor')
my_iris = cbind(my_iris, my_iris$Species=='virginica')
summary(my_iris)
names(my_iris)[6] = 'setosa'
names(my_iris)[7] = 'versicolor'
names(my_iris)[8] = 'virginica'
summary(my_iris)
amostra = sample(2,150,replace=T,prob=c(0.7,0.3))
my_iris_treino = my_iris[amostra == 1]
my_iris_teste = my_iris[amostra == 2]
my_iris_treino = my_iris[amostra == 1,]
my_iris_teste = my_iris[amostra == 2,]
dim(my_iris_treino)
dim(my_iris_teste)
modelo = neuralnet(setosa + versicolor + virginica ~ Sepal.Length + Sepal.Width + Sepal.Length + Petal.Width, my_iris_treino, hidden=c(5,4))
print(modelo)
plot(modelo)
plot(modelo)
View(modelo)
teste = compute(modelo, my_iris_teste[,1:4])
modelo = neuralnet(setosa + versicolor + virginica ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, my_iris_treino, hidden=c(5,4))
plot(modelo)
teste = compute(modelo, my_iris_teste[,1:4])
teste$net.result
resultado = ad.data.frame(teste$net.result)
resultado = as.data.frame(teste$net.result)
resultado$class = colnames(resultado[,1:3])[max.col(resultado[,1:3, ties.method='first'])]
resultado$class = colnames(resultado[,1:3])[max.col(resultado[,1:3], ties.method='first')]
head(resultado)
sum(diag(confusao) * 100 / sum(confusao))
confusao
library(neuralnet)
my_iris = iris
my_iris = cbind(my_iris, my_iris$Species=='setosa')
my_iris = cbind(my_iris, my_iris$Species=='versicolor')
my_iris = cbind(my_iris, my_iris$Species=='virginica')
summary(my_iris)
names(my_iris)[6] = 'setosa'
names(my_iris)[7] = 'versicolor'
names(my_iris)[8] = 'virginica'
summary(my_iris)
amostra = sample(2,150,replace=T,prob=c(0.7,0.3))
my_iris_treino = my_iris[amostra == 1,]
my_iris_teste = my_iris[amostra == 2,]
dim(my_iris_treino)
dim(my_iris_teste)
modelo = neuralnet(setosa + versicolor + virginica ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, my_iris_treino, hidden=c(5,4))
plot(modelo)
teste = compute(modelo, my_iris_teste[,1:4])
teste$net.result
resultado = as.data.frame(teste$net.result)
names(resultado[1] = 'setosa')
names(resultado[2] = 'versicolor')
names(resultado[3] = 'virginica')
names(resultado)[1] = 'setosa'
names(resultado)[2] = 'versicolor'
names(resultado)[3] = 'virginica'
resultado$class = colnames(resultado[,1:3])[max.col(resultado[,1:3], ties.method='first')]
head(resultado)
confusao = table(resultado$class, my_iris_teste$Species)
sum(diag(confusao) * 100 / sum(confusao))
confusao
digitos = read.csv(gzfile(file.choose(), header=F))
digitos = read.csv(gzfile(file.choose()), header=F)
dim(digitos)
plot(modelo)
dim(digitos)
head(digitos)
split.screen(figs=c(2,2))
dig = t(matrix(unlist(digitos[20, -785], nrow=28, byrow=F)))
dig = t(matrix(unlist(digitos[20,-785]), nrow = 28, byrow = F))
dig = t(apply(dig, 2, rev))
dig
image(dig, col=grey.colors(s255))
image(dig, col=gray.colors(s255))
image(dig, col=grey.colors(255))
digitos[20,785]
screen(2)
dig = t(matrix(unlist(digitos[2,-785]), nrow = 28, byrow = F))
dig = t(matrix(unlist(digitos[2,-785]), nrow = 28, byrow = F))
image(dig, col=grey.colors(255))
digitos[2,785]
screen(3)
dig = t(matrix(unlist(digitos[4,-785]), nrow = 28, byrow = F))
image(dig, col=grey.colors(255))
digitos[4,785]
screen(4)
dig = t(matrix(unlist(digitos[5,-785]), nrow = 28, byrow = F))
image(dig, col=grey.colors(255))
digitos[5,785]
#treinamento da rede
install.packages("h2o")
library(h2o)
library(h2o)
h2o.init()
treino = h2o.importFile(file.choose())
h2o.init()
h2o.init()
treino = h2o.importFile(file.choose())
teste = h2o.importFile(file.choose())
treino = h2o.importFile(file.choose())
teste = h2o.importFile(file.choose())
treino[,785] = as.factor(treino[,785])
teste[,785] = as.factor(teste[,785])
modelo = h2o.deeplearning(x=colnames(treino[,1:784], y="C785", training_frame=treino, validation_frame=teste, distribution="AUTO", activation="RectifierWithDropout", hidden=c(64,64,64), sparse=TRUE, epochs=20))
modelo = h2o.deeplearning(x=colnames(treino[,1:784]), y="C785", training_frame=treino, validation_frame=teste, distribution="AUTO", activation="RectifierWithDropout", hidden=c(64,64,64), sparse=TRUE, epochs=20)
plot(modelo)
plot(modelo)
close.screen(n, all.screens = FALSE)
close.screen(4, all.screens = FALSE)
plot(modelo)
close.screen(all=T)
plot(modelo)
h2o.performance(modelo)
treino[20,785]
pred = h2o.predict(modelo, newdata=treino[20,1:784])
pred$predict
plot(trees)
#dividindo a tela
split.screen(figs=c(2,2))
screen(1)
plot(trees$Girth, trees$Volume)
#dividindo a tela
split.screen(figs=c(2,2))
screen(1)
plot(trees$Girth, trees$Volume)
screen(2)
plot(trees$Girth, trees$Height)
screen(3)
plot(trees$Height, trees$Volume)
screen(4)
hist(trees$Volume)
#voltando tela
close.screen(all=TRUE)
boxplot(trees$Volume, main="Árvores", xlab="Volume")
boxplot(trees$Volume, main="Árvores", xlab="Volume", col="blue", horizontal=T)
boxplot(trees$Volume, main="Árvores", xlab="Volume", col="blue", horizontal=T, outline=F)
boxplot(trees$Volume, main="Árvores", xlab="Volume", col="blue", horizontal=T, outline=F, notch=T)
boxplot.stats(trees$Height)
boxplot(trees)
boxplot(trees, horizontal=T)
InsectSprays
spray =  aggregate(. ~ spray, data=InsectSprays, sum)
spray
#gráfico de barras
barplot(spray$count, col=gray.colors(6), xlab="Spray", ylab="Total", names.arg=spray$spray)
box()
#gráfico de setor (pizza)
pie(spray$count, labels=spray$spray, main="Spray", col=c(1:6))
legend("bottomright", legend=spray$spray, cex=1, fill=c(1:6))
pie(spray$count, labels=NA, main="Spray", col=c(1:6))
legend("bottomright", legend=spray$spray, cex=1, fill=c(1:6))
pie(spray$count, labels=NA, main="Spray", col=c(1:6))
legend("bottomright", legend=spray$spray, cex=1, fill=c(1:6))
#boxplot com Lattice
library(lattice)
bwplot(trees$Volume)
bwplot(trees$Volume main="Árvores", xlab="Volume")
bwplot(trees$Volume, main="Árvores", xlab="Volume")
#histograma com Lattice
library(lattice)
histogram(trees$Volume, main="Árvores", xlab="Volume", aspect=2, type="count", nint=10)
histogram(trees$Volume, main="Árvores", xlab="Volume", aspect=1, type="count", nint=10)
histogram(trees$Volume, main="Árvores", xlab="Volume", aspect=0.5, type="count", nint=10)
#usando chickwts para fazer histograma condicional
aggregate(chickwts$weight, by=list(chickwts$feed), FUN=sum)
histogram(~weight | feed, data=chickwts)
densityplot(CO2$conc)
density(~ CO2$conc | CO2$Treatment)
densityplot(~ CO2$conc | CO2$Treatment)
densityplot(~ CO2$conc | CO2$Treatment, plot.points=F)
#dispersão com Lattice
xyplot(CO2$conc ~ CO2$uptake)
xyplot(CO2$conc ~ CO2$uptake | CO2$Type)
xyplot(CO2$conc ~ CO2$uptake | CO2$Treatment)
esoph
dotplot(esoph$alcgp ~ esoph$controls, data=esoph)
dotplot(esoph$alcgp ~ esoph$ncontrols, data=esoph)
dotplot(esoph$alcgp ~ esoph$ncontrols | esoph$tobgp, data=esoph)
library(lattice)
cloud(decrease ~ rowpos * colpos, data=OrchardSprays)
cloud(decrease ~ rowpos * colpos, groups=treatment, data=OrchardSprays)
